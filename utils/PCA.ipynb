{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from data_master import DataMaster\n",
    "from utils import func\n",
    "from scipy.stats import norm\n",
    "master = DataMaster()\n",
    "from utils.func import center\n",
    "from quantstats.stats import sharpe\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_features = pd.read_parquet('data/US/market_features.pq')\n",
    "fundamental_features = pd.read_parquet('data/US/fundamental_features.pq')\n",
    "P = pd.read_parquet('data/US/test_adv_table.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GICS = pd.read_parquet('data/US/GICS.pq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features= market_features.join(fundamental_features,how = 'outer')\n",
    "# del fundamental_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = '2019'\n",
    "all_months = pd.to_datetime(P.index.strftime('%Y-%m')).tolist()\n",
    "trading_months =  pd.to_datetime(P.loc[START:].index.strftime('%Y-%m')).unique().tolist()\n",
    "trading_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = trading_months[-1]\n",
    "start_train = month - pd.DateOffset(months=1)\n",
    "end_train = month - pd.DateOffset(days=1)\n",
    "end_test = month + pd.DateOffset(months=1) - pd.DateOffset(days=1)\n",
    "training_data = all_features.sort_index(level=0).loc[start_train:end_train]\n",
    "P_training = P.loc[start_train:end_train]\n",
    "selected_tickers = P_training[P_training].iloc[-1].dropna().index.tolist()\n",
    "print(start_train,month,end_train,end_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_features.columns.tolist()\n",
    "NOT_USE = ['norm_daily_return',\n",
    "           'daily_returns',\n",
    "            'daily_vol',\n",
    "            'close',\n",
    "            'srs',\n",
    "            'month_of_year',\n",
    "            'year',\n",
    "            'date',\n",
    "            'target_returns',\n",
    "            'alpha_daily_returns',\n",
    "            'MVE',\n",
    "            'CASH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = training_data.drop(not_use,axis=1).columns.tolist()\n",
    "scaled_training_data = []\n",
    "for column in features:\n",
    "    training_data_column = training_data[column].unstack().reindex_like(P_training)[selected_tickers].ffill().fillna(0)\n",
    "    training_data_column = training_data_column.rank(axis=1,pct=True,ascending=True).clip(0.001,0.999).apply(norm.ppf)\n",
    "    training_data_column = training_data_column.resample('M').mean()\n",
    "    training_data_column = pd.DataFrame(training_data_column.stack(),columns = [column])\n",
    "    scaled_training_data.append(training_data_column)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "test = pd.concat(scaled_training_data,axis=1, join = 'outer').fillna(0)\n",
    "test\n",
    "pca = PCA(n_components=25)\n",
    "pca.fit(test)\n",
    "test_PCA = pca.fit_transform(test)\n",
    "test_PCA = test.copy() #pd.DataFrame(test_PCA,index = test.index)\n",
    "tickers = test_PCA.index.get_level_values(1).unique()\n",
    "sz = len(test_PCA.index.get_level_values(0).unique())\n",
    "n_ts =  len(test_PCA.index.get_level_values(1).unique())\n",
    "d = len(test_PCA.columns.tolist())\n",
    "test_PCA = test_PCA.swaplevel().sort_index(level=0)\n",
    "test_PCA_array = test_PCA.values.reshape(n_ts,sz,d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.generators import random_walks\n",
    "from tslearn.clustering import TimeSeriesKMeans, KernelKMeans\n",
    "km_dba = TimeSeriesKMeans(n_clusters=50, metric=\"dtw\", max_iter=20,\n",
    "                          max_iter_barycenter=20,\n",
    "                          random_state=0,verbose=0).fit(test_PCA_array)\n",
    "km_dba.cluster_centers_.shape\n",
    "stock_assigment = km_dba.predict(test_PCA_array)\n",
    "clusters = pd.DataFrame(stock_assigment,columns = [\"cluster\"],index = tickers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centerize(x):\n",
    "    x = x.rank(axis=1,pct=True,ascending=False).clip(0.001,0.999).apply(norm.ppf)\n",
    "    x = x.sub(x.mean(1),0)\n",
    "    return x\n",
    "metrics = market_features[\"norm_monthly_return\"].unstack().reindex_like(P)[selected_tickers]\n",
    "metrics = metrics.loc[month:end_test]\n",
    "metrics = metrics.groupby(clusters[\"cluster\"],axis=1).apply(centerize).droplevel(0,axis=1)\n",
    "metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centerize(x):\n",
    "    x = x.rank(axis=1,pct=True,ascending=False).clip(0.001,0.999).apply(norm.ppf)\n",
    "    x = x.sub(x.mean(1),0)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from tslearn.generators import random_walks\n",
    "from tslearn.clustering import TimeSeriesKMeans, KernelKMeans\n",
    "pnls = []\n",
    "signals =[]\n",
    "clusters_all = {}\n",
    "START = '2017'\n",
    "all_months = pd.to_datetime(P.index.strftime('%Y-%m')).tolist()\n",
    "trading_months =  pd.to_datetime(P.loc[START:].index.strftime('%Y-%m')).unique().tolist()\n",
    "SIGNAL_BASE =  market_features[\"norm_daily_return\"].unstack().reindex_like(P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = market_features['daily_returns'].unstack().reindex_like(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use range(start, stop, step) to iterate over every fourth element\n",
    "for i in tqdm(range(0, len(trading_months), 1)):\n",
    "    month = trading_months[i]\n",
    "    if month in list(clusters_all.keys()):\n",
    "        print(month,'done')\n",
    "        pass\n",
    "    else :\n",
    "        start_train = month - pd.DateOffset(months=1)\n",
    "        end_train = month - pd.DateOffset(days=1)\n",
    "        end_test = month + pd.DateOffset(months=1) - pd.DateOffset(days=1)\n",
    "        training_data = all_features.sort_index(level=0).loc[start_train:end_train]\n",
    "        P_training = P.loc[start_train:end_train]\n",
    "        selected_tickers = P_training[P_training].iloc[-1].dropna().index.tolist()\n",
    "        features = training_data.drop(not_use,axis=1).columns.tolist()\n",
    "        scaled_training_data = []\n",
    "        for column in features:\n",
    "            training_data_column = training_data[column].unstack().reindex_like(P_training)[selected_tickers].ffill().fillna(0)\n",
    "            training_data_column = training_data_column.rank(axis=1,pct=True,ascending=True).clip(0.001,0.999).apply(norm.ppf)\n",
    "            training_data_column = training_data_column.resample('M').mean()\n",
    "            training_data_column = pd.DataFrame(training_data_column.stack(),columns = [column])\n",
    "            scaled_training_data.append(training_data_column)\n",
    "        test = pd.concat(scaled_training_data,axis=1, join = 'outer').fillna(0)\n",
    "        pca = PCA(n_components=25)\n",
    "        # pca.fit(test)\n",
    "        test_PCA = test #pca.fit_transform(test)\n",
    "        test_PCA = pd.DataFrame(test_PCA,index = test.index)\n",
    "        tickers = test_PCA.index.get_level_values(1).unique()\n",
    "        sz = len(test_PCA.index.get_level_values(0).unique())\n",
    "        n_ts =  len(test_PCA.index.get_level_values(1).unique())\n",
    "        d = len(test_PCA.columns.tolist())\n",
    "        test_PCA = test_PCA.swaplevel().sort_index(level=0)\n",
    "        test_PCA_array = test_PCA.values.reshape(n_ts,sz,d)\n",
    "        km_dba = TimeSeriesKMeans(n_clusters=50, metric=\"dtw\", max_iter=10,\n",
    "                                max_iter_barycenter=10,\n",
    "                                random_state=0,verbose=0).fit(test_PCA_array)\n",
    "        stock_assigment = km_dba.predict(test_PCA_array)\n",
    "        clusters = pd.DataFrame(stock_assigment,columns = [\"cluster\"],index = tickers)\n",
    "        selected_tickers = clusters.index.tolist()\n",
    "        clusters_all[month] = clusters\n",
    "        signal = SIGNAL_BASE[selected_tickers].loc[month:end_test].copy()\n",
    "        signal = signal.groupby(clusters[\"cluster\"],axis=1).apply(centerize).droplevel(0,axis=1)\n",
    "        returns = R[selected_tickers].loc[month:end_test]\n",
    "        signal = signal.div(signal.abs().sum(1),0)\n",
    "        PNL = (signal.shift()*returns).dropna(axis=0,how = 'all').sum(1)\n",
    "        pnls.append(PNL)\n",
    "        signals.append(signal)\n",
    "        sr = sharpe(PNL)\n",
    "        turnover = signal.fillna(0).diff().abs().sum(1).mean()\n",
    "        PNL.cumsum().plot()\n",
    "        plt.show()\n",
    "        all_pnl = pd.concat(pnls)\n",
    "        all_pnl.cumsum().plot()\n",
    "        plt.show()\n",
    "        print(pd.Series({\n",
    "                'Sharpe':sr,\n",
    "                'total sharpe': sharpe(all_pnl),\n",
    "                'Daily Turnover (%)':turnover *100,\n",
    "                'biais (bp)':PNL.mean()*1e4,\n",
    "                'Sharpe since 2021' : sharpe(PNL.loc['2021':]),\n",
    "                'biais  since 2021 (bp)':PNL.loc['2022':].mean()*1e4}).round(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = market_features['daily_returns'].unstack().reindex_like(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done_months = list(clusters_all.keys())\n",
    "signal_features = {}\n",
    "all_pnls = []\n",
    "feature_source = market_features\n",
    "for feature in tqdm(list(feature_source)):\n",
    "    all_signal = []\n",
    "    metric = feature_source[feature].unstack().reindex_like(P)[P]\n",
    "    for month in (done_months) :\n",
    "        grp_cluster = clusters_all[month]\n",
    "        end_test = month + pd.DateOffset(months=1) - pd.DateOffset(days=1)\n",
    "        signal_month =  metric.loc[month: end_test][selected_tickers]\n",
    "        selected_tickers = grp_cluster.index.tolist()\n",
    "        signal_month = signal_month.groupby(grp_cluster[\"cluster\"],axis=1).apply(centerize).droplevel(0,axis=1)\n",
    "        signal_month = signal_month.div(signal_month.abs().sum(1),0)\n",
    "        all_signal.append(signal_month.dropna(axis=0,how='all'))\n",
    "    all_signal = pd.concat(all_signal,axis=0)\n",
    "    signal_features[feature] = all_signal\n",
    "    PNL = (all_signal.shift()*R).dropna(axis=0,how = 'all').sum(1)\n",
    "    PNL.name = feature\n",
    "    all_pnls.append(PNL)\n",
    "    # sr = sharpe(PNL)\n",
    "    # turnover = all_signal.fillna(0).diff().abs().sum(1).mean()\n",
    "    # PNL.cumsum().plot()\n",
    "    # plt.title(feature + str(sr))\n",
    "    # plt.show()\n",
    "    # print(pd.Series({'Sharpe':sr,\n",
    "    #     'Daily Turnover (%)':turnover *100,\n",
    "    #     'biais (bp)':PNL.mean()*1e4,\n",
    "    #     'Sharpe since 2022' : sharpe(PNL.loc['2022':]),\n",
    "    #     'biais  since 2022 (bp)':PNL.loc['2022':].mean()*1e4}).round(1))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "good = pd.concat(all_pnls,axis=1).apply(sharpe).abs().sort_values(ascending=False).head(10).index.tolist()\n",
    "pd.concat(all_pnls,axis=1)[good].drop('target_returns',axis=1).cumsum().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done_months = list(clusters_all.keys())\n",
    "signal_features = {}\n",
    "feature_source = market_features\n",
    "for feature in tqdm(feature_source.columns.tolist()):\n",
    "    all_signal = []\n",
    "    metric = feature_source[feature].unstack().reindex_like(P)\n",
    "    for month in (done_months[-39:]) :\n",
    "        grp_cluster = clusters_all[month]\n",
    "        end_test = month + pd.DateOffset(months=1) - pd.DateOffset(days=1)\n",
    "        signal_month =  metric.loc[month: end_test][selected_tickers]\n",
    "        selected_tickers = grp_cluster.index.tolist()\n",
    "        signal_month = pd.DataFrame().reindex_like(P).loc[month:end_test]\n",
    "        for cluster in grp_cluster['cluster'].unique().tolist():\n",
    "            tickers = clusters[clusters==cluster].dropna().index.tolist()\n",
    "            alpha = metric.loc[month:end_test].mean(1)\n",
    "            for ticker in tickers:\n",
    "                signal_month[ticker] = alpha\n",
    "        signal_month = signal_month.rank(axis=1,pct=True,ascending=True).clip(0.001,0.99).apply(norm.ppf)\n",
    "        signal_month = signal_month.sub(signal_month.mean(1),0)\n",
    "        signal_month = signal_month.div(signal_month.abs().sum(1),0)\n",
    "        all_signal.append(signal_month.dropna(axis=0,how='all'))\n",
    "    all_signal = pd.concat(all_signal,axis=0)\n",
    "    signal_features[feature] = all_signal\n",
    "    PNL = (all_signal.shift()*R).dropna(axis=0,how = 'all').sum(1)\n",
    "    sr = sharpe(PNL)\n",
    "    turnover = signal.fillna(0).diff().abs().sum(1).mean()\n",
    "    PNL.cumsum().plot()\n",
    "    plt.title(feature + str(sr))\n",
    "    plt.show()\n",
    "\n",
    "    print(pd.Series({'Sharpe':sr,\n",
    "                    'total sharpe': sharpe(all_pnl),\n",
    "        'Daily Turnover (%)':turnover *100,\n",
    "        'biais (bp)':PNL.mean()*1e4,\n",
    "        'Sharpe since 2022' : sharpe(PNL.loc['2022':]),\n",
    "        'biais  since 2022 (bp)':PNL.loc['2022':].mean()*1e4}).round(1))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_signals = pd.concat(signals).drop_duplicates(keep='first')\n",
    "# all_signals = all_signals.rank(ascending=True,pct=True,axis=1).clip(0.001,0.999).apply(norm.ppf)\n",
    "# # all_signals = all_signals[all_signals.abs()>0.5]\n",
    "# all_signals = all_signals.sub(all_signals.mean(1),0)\n",
    "# all_signals= all_signals.div(all_signals.abs().sum(1),0)\n",
    "all_signals= all_signals\n",
    "R = market_features['daily_returns'].unstack().reindex_like(P)  \n",
    "pnl = (all_signals.shift()*R).dropna(axis=0,how = 'all').sum(1)\n",
    "pnl.cumsum().plot()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
